import pandas as pd

# Columns that should be parsed as datetime
date_columns = [
    'Created Date', 'Closed Date', 'CISA KEV Due Date', 'CVE Published Date',
    'Spotlight Published Date', 'Host Last Seen Within', 'CISA KEV Due Date', 
    'Recommended Remediation Patch Publication Date', 'Patch Publication Date'
]

#Datatype Definitions
dtype_dict = {
    'Hostname': 'str',
    'LocalIP': 'str',
    'HostType': 'str',
    'OSVersion': 'str',
    'MachineDomain': 'str',
    'OU': 'str',
    'SiteName': 'str',
    'Product': 'str',
    'CVE ID': 'str',
    'CVE Description': 'str',
    'Status': 'str',
    'Severity': 'str',
    'Base Score': 'float64',
    'CVSS Version': 'Int64',
    'Vector': 'str',
    'Vendor Advisory': 'str',
    'References': 'str',
    'Recommended Remediations': 'str',
    'Remediation Details': 'str',
    'Remediation Links': 'str',
    'Group Names': 'str',
    'Tags': 'str',
    'Host ID': 'str',
    'Exploit status value': 'Int64',
    'Exploit status label': 'str',
    'Platform': 'str',
    'Vulnerable Product Versions': 'str',
    'Closed Product Versions': 'str',
    'RemediationLevel': 'str',
    'ExPRT Rating': 'str',
    'Is Suppressed': 'bool',
    'AdditionalRemediationAdvisoryUrl': 'str',
    'AdditionalRemediationSteps': 'str',
    'Is CISA KEV': 'bool',
    'Cloud Service Instance ID': 'str',
    'OS Build': 'str',
    'Asset Criticality': 'str',
    'Asset Roles': 'str',
    'Internet exposure': 'str',
    'Vulnerability ID': 'str',
    'Vulnerability Metadata ID': 'str',
    'Managed By': 'str',
    'Vulnerability Data Providers': 'str',
    'Third-party Asset IDs': 'str',
    'Third-party Scanner ID': 'str',
    'Ports': 'str',
    'Third-party Rating': 'str',
    'Last Scan Time': 'str',
    'Types': 'str',
    'CID': 'str',
    'Customer': 'str',
    'CWEs': 'str',
    'Vulnerability Confidence': 'str',
    'Asset Confidence Label': 'str',
    'Asset Subsidiaries': 'str',
    'Services Ports': 'str',
    'Services Transports': 'str',
    'Services Protocols': 'str',
    'Minimum Remediations': 'str',
    'Minimum Remediation Details': 'str',
    'Minimum Remediation Links': 'str',
    'Minimum Remediation Advisory URL': 'str',
    'Minimum Remediation Steps': 'str',
}



#Defile File Path
file_path = 'D:/Overflow - One Drive Filling up - Temporary/Projects/Cyber Security/Crowdstrike/Data Prep/20250219/Daily Windows Vulnerability Export - ALL - 20250219.csv'

#Load the CSV into a DataFrame
df = pd.read_csv(file_path, dtype=dtype_dict)

#check to see if data is being read properly
print(df.head(10).to_string())  # See full rows without truncation

#Troubleshooting step - identify unique error values
#print(df['Spotlight Published Date'].astype(str).unique())

#identify Datatype
#df.iloc[:, 40].unique()

#check to see if the column populated correctly
#df['Spotlight Published Date'].info()

#Try to convert Column 40 after import to correct dtype warning
#df['Spotlight Published Date'] = pd.to_datetime(df['Spotlight Published Date'], errors='coerce')

#Troubleshooting step - identify where pandas failed to parse a valid date
#print(df['Spotlight Published Date'][df['Spotlight Published Date'].isna()])



#Show the first few rows of the DataFrame
#print(df.head())

#Export Dataframe to .CSV
df.to_csv('D:/Overflow - One Drive Filling up - Temporary/Projects/Cyber Security/Crowdstrike/Data Prep/20250219/Daily Windows Vulnerability Export - ALL - 20250219 - test - a.csv', index=False, header=True)
