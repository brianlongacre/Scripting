# This cell creates two example interactive HTML animations (self-contained, offline) 
# to demonstrate approaches you can use with your vulnerability snapshots.
#
# Files produced:
# 1) /mnt/data/animated_severity_trend.html  -> Animated line chart over time by severity
# 2) /mnt/data/animated_bar_race_products.html -> Animated bar chart race of product counts
# 3) /mnt/data/vuln_animator_template.py -> A template script you can adapt to your real data
#
# You can download them from the links I'll share after this runs.

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.express as px
from pathlib import Path

out_dir = Path("/mnt/data")
out_dir.mkdir(parents=True, exist_ok=True)

# -------------------------------
# 1) Build a small synthetic dataset for an animated severity trend
# -------------------------------
np.random.seed(42)

start_date = datetime(2024, 10, 1)
weeks = 24  # 24 frames
dates = [start_date + timedelta(weeks=i) for i in range(weeks)]
severities = ["Critical", "High", "Medium", "Low"]

rows = []
base = {"Critical": 150, "High": 400, "Medium": 900, "Low": 1200}
# Add some synthetic dynamics over time (new/closed noise)
for d_i, d in enumerate(dates):
    season = np.sin(d_i / 4.0)  # seasonal-ish trend
    for sev in severities:
        drift = (0.02 if sev in ["Critical", "High"] else -0.01) * d_i
        noise = np.random.randint(-40, 40)
        val = max(0, int(base[sev] * (1 + 0.1 * season + drift) + noise))
        rows.append({"snapshot_date": d.date().isoformat(), "severity": sev, "open_count": val})

df_sev = pd.DataFrame(rows)

fig1 = px.line(
    df_sev,
    x="snapshot_date",
    y="open_count",
    color="severity",
    title="Open Vulnerabilities Over Time by Severity (Animated)",
    markers=True,
    labels={"snapshot_date": "Snapshot Date", "open_count": "Open Vulnerabilities"},
    animation_frame="snapshot_date",
    range_y=[0, df_sev["open_count"].max() * 1.1],
)
# Make animation a bit smoother
fig1.layout.updatemenus[0].buttons[0].args[1]["frame"]["duration"] = 350
fig1.layout.updatemenus[0].buttons[0].args[1]["transition"]["duration"] = 200

severity_html = out_dir / "animated_severity_trend.html"
fig1.write_html(severity_html, include_plotlyjs="inline", full_html=True)

# -------------------------------
# 2) Synthetic dataset for an animated bar chart race (top products over time)
# -------------------------------
products = [f"Prod-{i:02d}" for i in range(1, 16)]
rows = []
for d_i, d in enumerate(dates):
    # pick a few "hot" products that change over time
    hot_start = (d_i // 6) * 5  # rotate which products are hot each ~6 weeks
    for p_i, p in enumerate(products):
        base_val = 50 + (10 * ((p_i + d_i) % 5))  # staggered baseline
        hot_bonus = 120 if hot_start <= p_i < hot_start + 5 else 0
        noise = np.random.randint(0, 50)
        val = base_val + hot_bonus + noise
        rows.append(
            {
                "snapshot_date": d.date().isoformat(),
                "product": p,
                "open_count": int(val),
            }
        )

df_prod = pd.DataFrame(rows)

# Keep the "top 10" each frame so the race is readable
def top_k_per_date(df, k=10):
    return (
        df.sort_values(["snapshot_date", "open_count"], ascending=[True, False])
          .groupby("snapshot_date")
          .head(k)
          .reset_index(drop=True)
    )

df_prod_top10 = top_k_per_date(df_prod, 10)

fig2 = px.bar(
    df_prod_top10.sort_values(["snapshot_date", "open_count"]),
    x="open_count",
    y="product",
    color="product",
    orientation="h",
    animation_frame="snapshot_date",
    range_x=[0, df_prod_top10["open_count"].max() * 1.1],
    title="Top 10 Products by Open Vulnerabilities (Bar Chart Race)",
    labels={"open_count": "Open Vulnerabilities", "product": "Product"},
)
# Ensure bars are sorted within each frame
fig2.update_yaxes(categoryorder="total ascending")
fig2.layout.updatemenus[0].buttons[0].args[1]["frame"]["duration"] = 400
fig2.layout.updatemenus[0].buttons[0].args[1]["transition"]["duration"] = 200

bar_race_html = out_dir / "animated_bar_race_products.html"
fig2.write_html(bar_race_html, include_plotlyjs="inline", full_html=True)

# -------------------------------
# 3) Template script the user can adapt to their real data
# -------------------------------
template = r'''#!/usr/bin/env python3
"""
vuln_animator_template.py

Purpose:
    - Ingest historical vulnerability snapshots (CSV/JSON) from dated folders
    - Produce self-contained interactive HTML animations (no internet required)
      using Plotly with embedded plotly.js.

Assumptions (adjust to your environment):
    - Folder hierarchy like: YYYYmmdd/
        - Daily Other Vulnerability Export - ALL - YYYYmmdd.csv
        - Daily Closed Vulnerability Export - ALL - YYYYmmdd.csv
        - Daily Remediation Export - ALL - YYYYmmdd.csv
    - Or use your SQL-ready exports with consistent columns.

Outputs:
    - animated_severity_trend.html
    - animated_bar_race_products.html

How to run:
    python vuln_animator_template.py --root "X:/path/to/snapshots" --pattern "Daily Other Vulnerability Export - ALL - *.csv"
    (You can pass multiple --pattern flags.)

Notes:
    - This script only needs Python + pandas + plotly installed.
    - The resulting HTML files are single-file, portable, and work in modern browsers.
"""

import argparse
from pathlib import Path
import re
import pandas as pd
import plotly.express as px

def infer_date_from_name(name: str):
    # Try to find an 8-digit yyyymmdd in file or folder names
    m = re.search(r'(20\d{6})', name)
    return m.group(1) if m else None

def load_files(root: Path, patterns):
    files = []
    for pat in patterns:
        files.extend(root.rglob(pat))
    return sorted(files)

def canonicalize(df: pd.DataFrame) -> pd.DataFrame:
    """
    Map your columns into a canonical set used for visuals.
    Expect (adjust as needed):
        - snapshot_date (YYYY-mm-dd)
        - severity (Critical/High/Medium/Low)
        - product (or application / package name)
        - open_count (int)
    If your raw exports are per-CVE/Host, aggregate counts here.
    """
    # --- EXAMPLE MAPPING ---
    cols = {c.lower().strip(): c for c in df.columns}

    # Try to find likely fields (adjust mapping for your real columns)
    # Examples given your previous notes:
    # - "CVE-ID" per host -> aggregate counts per snapshot/severity/product
    # - severity might be in "severity" or "exprt_rating" etc.
    severity_col = next((c for c in df.columns if c.lower() in {"severity", "exprt_rating"}), None)
    product_col  = next((c for c in df.columns if c.lower() in {"product", "application", "app_name"}), None)

    # Fallbacks for demo; replace with your mapping
    if severity_col is None:
        df["severity"] = "Unknown"
        severity_col = "severity"
    if product_col is None:
        df["product"] = "Unknown"
        product_col = "product"

    # Standardize severity casing
    df[severity_col] = df[severity_col].astype(str).str.title()

    # If this file is already an aggregate, ensure open_count exists; else count rows
    if "open_count" not in df.columns:
        df["open_count"] = 1

    return df.rename(columns={severity_col: "severity", product_col: "product"})

def build_master_table(root: Path, patterns):
    records = []
    for f in load_files(root, patterns):
        snap_raw = infer_date_from_name(str(f))
        # Normalize to YYYY-mm-dd if we got yyyymmdd
        if snap_raw and re.fullmatch(r"20\d{6}", snap_raw):
            snapshot_date = f"{snap_raw[:4]}-{snap_raw[4:6]}-{snap_raw[6:]}"
        else:
            snapshot_date = None

        df = pd.read_csv(f, low_memory=False)
        df = canonicalize(df)
        df["snapshot_date"] = snapshot_date or ""

        # Keep only relevant columns
        df = df[["snapshot_date", "severity", "product", "open_count"]]
        records.append(df)

    if not records:
        raise SystemExit("No files found. Check --root and --pattern flags.")

    all_df = pd.concat(records, ignore_index=True)

    # If data is per-row (host/CVE), you likely want to aggregate for visuals:
    # Severity trend over time
    df_sev = (all_df
              .groupby(["snapshot_date", "severity"], dropna=False, as_index=False)["open_count"]
              .sum())

    # Top products per snapshot
    df_prod = (all_df
               .groupby(["snapshot_date", "product"], dropna=False, as_index=False)["open_count"]
               .sum())

    return df_sev, df_prod

def make_severity_animation(df_sev: pd.DataFrame, out_path: Path):
    # Ensure proper sort by date
    df_sev = df_sev.sort_values("snapshot_date")
    fig = px.line(
        df_sev,
        x="snapshot_date",
        y="open_count",
        color="severity",
        markers=True,
        title="Open Vulnerabilities Over Time by Severity (Animated)",
        labels={"snapshot_date": "Snapshot Date", "open_count": "Open Vulnerabilities"},
        animation_frame="snapshot_date",
    )
    # Tidy animation pacing
    fig.layout.updatemenus[0].buttons[0].args[1]["frame"]["duration"] = 350
    fig.layout.updatemenus[0].buttons[0].args[1]["transition"]["duration"] = 200
    fig.write_html(out_path, include_plotlyjs="inline", full_html=True)

def make_bar_race(df_prod: pd.DataFrame, out_path: Path, top_k=10):
    # Top K per snapshot
    df_top = (df_prod.sort_values(["snapshot_date", "open_count"], ascending=[True, False])
              .groupby("snapshot_date", as_index=False)
              .head(top_k))
    fig = px.bar(
        df_top.sort_values(["snapshot_date", "open_count"]),
        x="open_count",
        y="product",
        color="product",
        orientation="h",
        animation_frame="snapshot_date",
        labels={"open_count": "Open Vulnerabilities", "product": "Product"},
        title=f"Top {top_k} Products by Open Vulnerabilities (Bar Chart Race)",
    )
    fig.update_yaxes(categoryorder="total ascending")
    fig.layout.updatemenus[0].buttons[0].args[1]["frame"]["duration"] = 400
    fig.layout.updatemenus[0].buttons[0].args[1]["transition"]["duration"] = 200
    fig.write_html(out_path, include_plotlyjs="inline", full_html=True)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--root", required=True, help="Root folder containing dated snapshot folders/files")
    ap.add_argument("--pattern", action="append", required=True,
                    help="Glob pattern(s) relative to root (e.g., 'Daily Other Vulnerability Export - ALL - *.csv')")
    ap.add_argument("--topk", type=int, default=10, help="Top K products in bar race")
    ap.add_argument("--outdir", default=".", help="Output directory for HTML files")
    args = ap.parse_args()

    root = Path(args.root)
    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    df_sev, df_prod = build_master_table(root, args.pattern)

    make_severity_animation(df_sev, outdir / "animated_severity_trend.html")
    make_bar_race(df_prod, outdir / "animated_bar_race_products.html", top_k=args.topk)

    print("Done. Outputs:")
    print(outdir / "animated_severity_trend.html")
    print(outdir / "animated_bar_race_products.html")

if __name__ == "__main__":
    main()
'''
template_path = out_dir / "vuln_animator_template.py"
template_path.write_text(template, encoding="utf-8")

str(severity_html), str(bar_race_html), str(template_path)
